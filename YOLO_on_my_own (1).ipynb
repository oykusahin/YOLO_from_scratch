{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_on_my_own.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S42tfe51x2EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install tensorflow-gpu==2.0.0\n",
        "! pip install --upgrade keras\n",
        "! pip install opencv-python\n",
        "! pip install pillow Cython lxml jupyter matplotlib\n",
        "! pip install -q tensorflow tensorflow-datasets matplotlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKLey4_KtCDp",
        "colab_type": "code",
        "outputId": "e573e525-1b19-49e6-bd9a-189e3f7798bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "import struct\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh3KxrMr6ECp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_train = tfds.load(name='voc', split='train')\n",
        "assert isinstance(voc_train, tf.data.Dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSlMhUmnqWdo",
        "colab_type": "code",
        "outputId": "d2c91cb0-b3b0-461e-d9b4-512b24c730b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes= {}\n",
        "voc_builder = tfds.builder(\"voc\")\n",
        "info = voc_builder.info\n",
        "\n",
        "for i in range(len(info.features[\"labels\"].names)):\n",
        "  classes[i] = info.features[\"labels\"].names[i]\n",
        "\n",
        "len(classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IYHf9yivosZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5281f9-10ae-4052-c8f2-4ddc15cc0d9c"
      },
      "source": [
        "y_train = []\n",
        "X_train = []\n",
        "temp_labels = [0]*(len(classes)+1)\n",
        "\n",
        "for voc_example in voc_train.take(1):\n",
        "  image, label, objects = voc_example['image'], voc_example['labels'], voc_example['objects']\n",
        "  \n",
        "  image =tf.image.resize_with_crop_or_pad(image, 448, 448)\n",
        "  image = image.numpy()\n",
        "  image = np.asarray( image ) / 255.0\n",
        "  X_train=np.append( X_train , image)\n",
        "  \n",
        "  label = label.numpy()\n",
        "\n",
        "  bbox = objects['bbox']\n",
        "  bbox = bbox.numpy()  \n",
        "\n",
        "  #[[classscore],[x1],[y1],[x2],[y2], [one-hot encoding label]]\n",
        "  labels= np.append(label, 20)\n",
        "  labels = to_categorical(labels)\n",
        "  for k in range(len(labels)):\n",
        "    temp_labels = temp_labels + labels[k]\n",
        "  print(temp_labels)\n",
        "  for i in range(len(bbox[0])):\n",
        "    temp_array=[]\n",
        "    temp_array= np.append(temp_array, 1)\n",
        "    temp_array= np.append(temp_array, [bbox[i,0], bbox[i,1], bbox[i,2], bbox[i,3]]) \n",
        "    temp_array = np.append(temp_array, temp_labels[0:20])\n",
        "    y_train = np.append(y_train, temp_array)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuO24BJIkLRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.reshape(y_train,(4,25))\n",
        "y_train\n",
        "X_train= X_train.reshape((1,448, 448, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScSlh7yW2XOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_cfg(cfgfile):\n",
        "    file = open(cfgfile, 'r')\n",
        "    lines = file.read().split('\\n')                        # store the lines in a list\n",
        "    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
        "    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
        "    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n",
        "\n",
        "    block = {}\n",
        "    blocks = []\n",
        "\n",
        "    for line in lines:\n",
        "      if line[0] == \"[\":               # This marks the start of a new block\n",
        "        if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n",
        "          blocks.append(block)     # add it the blocks list\n",
        "          block = {}               # re-init the block\n",
        "        block[\"type\"] = line[1:-1].rstrip()    \n",
        "      else:\n",
        "        key,value = line.split(\"=\")\n",
        "        block[key.rstrip()] = value.lstrip()\n",
        "    blocks.append(block)\n",
        "    return blocks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ3yuzUq-Ljg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename= \"/content/gdrive/My Drive/Colab Notebooks/sample_data/darknet53.cfg.txt\"\n",
        "blocks = parse_cfg(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz4IqL7K3Xbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_modules(blocks, model):\n",
        "    net_info = blocks[0]         \n",
        "    prev_filters = 3\n",
        "    output_filters = []\n",
        "\n",
        "    for index, x in enumerate(blocks[1:]):\n",
        "      if (x[\"type\"] == \"convolutional\"):\n",
        "        print(\"Conv2d\")\n",
        "        activation = x[\"activation\"]\n",
        "        try:\n",
        "          batch_normalize = int(x[\"batch_normalize\"])\n",
        "          bias = False\n",
        "        except:\n",
        "          batch_normalize = 0\n",
        "          bias = True\n",
        "\n",
        "        filters= int(x[\"filters\"])\n",
        "        padding = int(x[\"pad\"])\n",
        "        kernel_size = int(x[\"size\"])\n",
        "        strides = int(x[\"stride\"])\n",
        "\n",
        "        if padding:\n",
        "          pad = (kernel_size - 1) // 2\n",
        "        else:\n",
        "          pad = 0\n",
        "            \n",
        "        #Add the convolutional layer\n",
        "        model.add(Conv2D(input_shape = (608,608,3), filters = filters, kernel_size = kernel_size, strides = (strides, strides)))\n",
        "    \n",
        "        #Add the Batch Norm Layer\n",
        "        if batch_normalize:\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            #Check the activation. \n",
        "            #It is either Linear or a Leaky ReLU for YOLO\n",
        "        if activation == \"leaky\":\n",
        "          activn = LeakyReLU(0.1)\n",
        "          model.add(activn)\n",
        "\n",
        "        #If it's an upsampling layer\n",
        "        #We use Bilinear2dUpsampling\n",
        "      elif (x[\"type\"] == \"upsample\"):\n",
        "        print(\"Upsample\")\n",
        "        stride = int(x[\"stride\"])\n",
        "        model.add(UpSampling2D(size=2,interpolation=\"bilinear\"))\n",
        "       \n",
        "       #If it is a route layer\n",
        "      elif (x[\"type\"] == \"route\"):\n",
        "        print(\"Route\")\n",
        "        start=0\n",
        "        end =0\n",
        "        if len(x[\"layers\"]) == 1:\n",
        "          start = x[\"layers\"][0]\n",
        "        else:\n",
        "          #end, if there exists one.\n",
        "          try:\n",
        "            end = int(x[\"layers\"][1])\n",
        "          except:\n",
        "            end = 0\n",
        "          #Positive anotation\n",
        "\n",
        "        if start > 0: \n",
        "          start = start - index\n",
        "        if end > 0:\n",
        "          end = end - index\n",
        "          model.add(EmptyLayer())\n",
        "\n",
        "      #shortcut corresponds to skip connection\n",
        "      elif x[\"type\"] == \"shortcut\":\n",
        "        print(\"shortcut\")\n",
        "        #shortcut = EmptyLayer()\n",
        "        model.add(EmptyLayer())\n",
        "      \n",
        "      elif x[\"type\"] == \"yolo\":\n",
        "        print(\"yolo\")\n",
        "        mask = x[\"mask\"].split(\",\")\n",
        "        mask = [int(x) for x in mask]\n",
        "\n",
        "        anchors = x[\"anchors\"].split(\",\")\n",
        "        anchors = [int(a) for a in anchors]\n",
        "        anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
        "        anchors = [anchors[i] for i in mask]\n",
        "\n",
        "        #detection = DetectionLayer(anchors)\n",
        "        model.add(DetectionLayer(anchors))\n",
        "        #module.add_module(\"Detection_{}\".format(index), detection)\n",
        "\n",
        "    return net_info, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-81y_BIA66a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "\n",
        "class EmptyLayer(Layer):\n",
        "    def __init__(self):\n",
        "        super(EmptyLayer, self).__init__()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex1BmZCICy0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DetectionLayer(Layer):\n",
        "    def __init__(self, anchors):\n",
        "        super(DetectionLayer, self).__init__()\n",
        "        self.anchors = anchors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afmcqa_l-CCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "net_info, model = create_modules(blocks,model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lx_Lah0VyRS",
        "colab_type": "code",
        "outputId": "2ff8290b-3d64-4071-b5d6-e8ff59d8ea20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m                 \u001b[0;34m'Build the model first by calling build() '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m                 \u001b[0;34m'or calling fit() with some data. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_cq6RKl7vyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_rate = 0.5\n",
        "alpha = 0.2\n",
        "\n",
        "def calculate_iou( target_boxes , pred_boxes ):\n",
        "    xA = K.maximum( target_boxes[ ... , 0], pred_boxes[ ... , 0] )\n",
        "    yA = K.maximum( target_boxes[ ... , 1], pred_boxes[ ... , 1] )\n",
        "    xB = K.minimum( target_boxes[ ... , 2], pred_boxes[ ... , 2] )\n",
        "    yB = K.minimum( target_boxes[ ... , 3], pred_boxes[ ... , 3] )\n",
        "    interArea = K.maximum( 0.0 , xB - xA ) * K.maximum( 0.0 , yB - yA )\n",
        "    boxAArea = (target_boxes[ ... , 2] - target_boxes[ ... , 0]) * (target_boxes[ ... , 3] - target_boxes[ ... , 1])\n",
        "    boxBArea = (pred_boxes[ ... , 2] - pred_boxes[ ... , 0]) * (pred_boxes[ ... , 3] - pred_boxes[ ... , 1])\n",
        "    iou = interArea / ( boxAArea + boxBArea - interArea )\n",
        "    return iou\n",
        "\n",
        "def custom_loss( y_true , y_pred ):\n",
        "    mse = tf.losses.mean_squared_error( y_true , y_pred ) \n",
        "    iou = calculate_iou( y_true , y_pred ) \n",
        "    return mse + ( 1 - iou )\n",
        "\n",
        "def iou_metric( y_true , y_pred ):\n",
        "    return calculate_iou( y_true , y_pred )\n",
        "\t\t\n",
        "class BoundBox:\n",
        "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "\t\tself.xmin = xmin\n",
        "\t\tself.ymin = ymin\n",
        "\t\tself.xmax = xmax\n",
        "\t\tself.ymax = ymax\n",
        "\t\tself.objness = objness\n",
        "\t\tself.classes = classes\n",
        "\t\tself.label = -1\n",
        "\t\tself.score = -1\n",
        " \n",
        "\tdef get_label(self):\n",
        "\t\tif self.label == -1:\n",
        "\t\t\tself.label = np.argmax(self.classes)\n",
        " \n",
        "\t\treturn self.label\n",
        " \n",
        "\tdef get_score(self):\n",
        "\t\tif self.score == -1:\n",
        "\t\t\tself.score = self.classes[self.get_label()]\n",
        " \n",
        "\t\treturn self.score\n",
        " \n",
        "def _sigmoid(x):\n",
        "\treturn 1. / (1. + np.exp(-x))\n",
        " \n",
        "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
        "\tgrid_h, grid_w = netout.shape[:2]\n",
        "\tnb_box = 3\n",
        "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "\tnb_class = netout.shape[-1] - 5\n",
        "\tboxes = []\n",
        "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        " \n",
        "\tfor i in range(grid_h*grid_w):\n",
        "\t\trow = i / grid_w\n",
        "\t\tcol = i % grid_w\n",
        "\t\tfor b in range(nb_box):\n",
        "\t\t\t# 4th element is objectness score\n",
        "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
        "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
        "\t\t\t# first 4 elements are x, y, w, and h\n",
        "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
        "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
        "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\t\t\t# last elements are class probabilities\n",
        "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
        "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "\t\t\tboxes.append(box)\n",
        "\treturn boxes\n",
        " \n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "\tnew_w, new_h = net_w, net_h\n",
        "\tfor i in range(len(boxes)):\n",
        "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        " \n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "\tx1, x2 = interval_a\n",
        "\tx3, x4 = interval_b\n",
        "\tif x3 < x1:\n",
        "\t\tif x4 < x1:\n",
        "\t\t\treturn 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x1\n",
        "\telse:\n",
        "\t\tif x2 < x3:\n",
        "\t\t\t return 0\n",
        "\t\telse:\n",
        "\t\t\treturn min(x2,x4) - x3\n",
        " \n",
        "def bbox_iou(box1, box2):\n",
        "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\tintersect = intersect_w * intersect_h\n",
        "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\tunion = w1*h1 + w2*h2 - intersect\n",
        "\treturn float(intersect) / union\n",
        " \n",
        "def do_nms(boxes, nms_thresh):\n",
        "\tif len(boxes) > 0:\n",
        "\t\tnb_class = len(boxes[0].classes)\n",
        "\telse:\n",
        "\t\treturn\n",
        "\tfor c in range(nb_class):\n",
        "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\t\tfor i in range(len(sorted_indices)):\n",
        "\t\t\tindex_i = sorted_indices[i]\n",
        "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
        "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
        "\t\t\t\tindex_j = sorted_indices[j]\n",
        "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "\t\t\t\t\tboxes[index_j].classes[c] = 0\n",
        " \n",
        "def load_image_pixels(filename, shape):\n",
        "\timage = load_img(filename)\n",
        "\twidth, height = image.size\n",
        "\timage = load_img(filename, target_size=shape)\n",
        "\timage = img_to_array(image)\n",
        "\timage = image.astype('float32')\n",
        "\timage /= 255.0\n",
        "\timage = expand_dims(image, 0)\n",
        "\treturn image, width, height\n",
        " \n",
        "def get_boxes(boxes, labels, thresh):\n",
        "\tv_boxes, v_labels, v_scores = list(), list(), list()\n",
        "\tfor box in boxes:\n",
        "\t\tfor i in range(len(labels)):\n",
        "\t\t\tif box.classes[i] > thresh:\n",
        "\t\t\t\tv_boxes.append(box)\n",
        "\t\t\t\tv_labels.append(labels[i])\n",
        "\t\t\t\tv_scores.append(box.classes[i]*100)\n",
        "\treturn v_boxes, v_labels, v_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq45dprDFhQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "\tdata = pyplot.imread(filename)\n",
        "\tpyplot.imshow(data)\n",
        "\tax = pyplot.gca()\n",
        "\tfor i in range(len(v_boxes)):\n",
        "\t\tbox = v_boxes[i]\n",
        "\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
        "\t\tax.add_patch(rect)\n",
        "\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "\t\tpyplot.text(x1, y1, label, color='white')\n",
        "\tpyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHhITWBFh2Rf",
        "colab_type": "code",
        "outputId": "60bbc2f7-84ac-40b8-f422-acbaaacd4031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "#####SCRATCHBOOK########\n",
        "for voc_example in voc_train.take(10):\n",
        "  image= voc_example['image']\n",
        "  #image = np.reshape(image, (448,448,3))\n",
        "  label = voc_example['labels']\n",
        "  objects = voc_example['objects']\n",
        "  bbox = objects['bbox']\n",
        "  #x=tf.concat([image, x], 0)\n",
        "  x=tf.image.resize_with_crop_or_pad(image, 448, 448)\n",
        "  x=tf.reshape(x,(5,))\n",
        "  x=bbox.numpy()\n",
        "  print(x)\n",
        "  #print(label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.14375    0.0437018  0.97083336 0.7763496 ]\n",
            " [0.14583333 0.24164525 0.57916665 0.6066838 ]\n",
            " [0.6        0.5244216  0.8541667  0.76606685]\n",
            " [0.56041664 0.5012854  0.7395833  0.6863753 ]]\n",
            "[[0.07466666 0.08       0.88533336 0.812     ]\n",
            " [0.304      0.002      0.73866665 0.292     ]]\n",
            "[[0.264 0.006 1.    1.   ]]\n",
            "[[0.138      0.00533333 0.998      0.9813333 ]]\n",
            "[[0.3153153 0.314     0.8318318 0.932    ]]\n",
            "[[0.18933333 0.002      1.         0.352     ]\n",
            " [0.00533333 0.3        1.         1.        ]]\n",
            "[[0.424      0.208      0.986      0.84533334]\n",
            " [0.196      0.02933333 0.482      0.8746667 ]\n",
            " [0.272      0.21866667 0.756      0.85866666]]\n",
            "[[0.16533333 0.158      1.         1.        ]]\n",
            "[[0.59516615 0.194      0.7703928  0.286     ]\n",
            " [0.68882173 0.058      0.9848943  0.188     ]\n",
            " [0.5861027  0.658      0.7734139  0.75      ]\n",
            " [0.6676737  0.754      0.91540784 0.88      ]\n",
            " [0.5861027  0.104      0.978852   0.876     ]]\n",
            "[[0.2072072 0.028     0.6576577 0.974    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AchRVHBKUAsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = createModel()\n",
        "batch_size = 256\n",
        "epochs = 50\n",
        "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model1.fit(X_train, Y_train)\n",
        "model1.evaluate(test_data, test_labels_one_hot)\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLji1F1uEuTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##TODO: skip layers, residual blocks\n",
        "def createModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=(2,2), activation=\"relu\"))\n",
        "        \n",
        "    model.add(Conv2D(32, kernel_size=1, strides=(1,1), activation=\"relu\"))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "    \n",
        "    model.add(Conv2D(128, kernel_size=3, strides=(2,2), activation=\"relu\"))\n",
        "    \n",
        "    for _ in range(2):\n",
        "      model.add(Conv2D(64, kernel_size=3,  strides=(1,1), activation=\"relu\"))\n",
        "      model.add(Conv2D(128, kernel_size=3, strides=(1,1),activation=\"relu\"))\n",
        "    \n",
        "    model.add(Conv2D(256, kernel_size=3, strides=(2,2), activation=\"relu\"))\n",
        "    for _ in range(8):\n",
        "      model.add(Conv2D(128, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "      model.add(Conv2D(256, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "    \n",
        "    model.add(Conv2D(512, kernel_size=3, strides=(2,2), activation=\"relu\"))\n",
        "    for _ in range(8):\n",
        "      model.add(Conv2D(256, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "      model.add(Conv2D(512, kernel_size=3, strides=(1,1), activation=\"relu\"))\n",
        "    \n",
        "    model.add(Conv2D(1024, kernel_size=3, strides=(2,2), activation=\"relu\"))\n",
        "    for _ in range(4):\n",
        "      model.add(Conv2D(512, kernel_size=3, activation=\"relu\"))\n",
        "      model.add(Conv2D(1024, kernel_size=3, activation=\"relu\"))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYaBbvYkQPa7",
        "colab_type": "code",
        "outputId": "b3b7adc8-8db1-490c-f3e0-6b70b8c8ed96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "source": [
        "voc_builder = tfds.builder(\"voc\")\n",
        "info = voc_builder.info\n",
        "print(info)\n",
        "print(info.features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='voc',\n",
            "    version=4.0.0,\n",
            "    description='This dataset contains the data from the PASCAL Visual Object Classes Challenge\n",
            "2007, a.k.a. VOC2007, corresponding to the Classification and Detection\n",
            "competitions.\n",
            "A total of 9963 images are included in this dataset, where each image\n",
            "contains a set of objects, out of 20 different classes, making a total of\n",
            "24640 annotated objects.\n",
            "In the Classification competition, the goal is to predict the set of labels\n",
            "contained in the image, while in the Detection competition the goal is to\n",
            "predict the bounding box and label of each individual object.\n",
            "WARNING: As per the official dataset, the test set of VOC2012 does not contain\n",
            "annotations.\n",
            "',\n",
            "    homepage='http://host.robots.ox.ac.uk/pascal/VOC/voc2007/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
            "        'image/filename': Text(shape=(), dtype=tf.string),\n",
            "        'labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
            "        'labels_no_difficult': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
            "        'objects': Sequence({\n",
            "            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
            "            'is_difficult': Tensor(shape=(), dtype=tf.bool),\n",
            "            'is_truncated': Tensor(shape=(), dtype=tf.bool),\n",
            "            'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),\n",
            "            'pose': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
            "        }),\n",
            "    }),\n",
            "    total_num_examples=9963,\n",
            "    splits={\n",
            "        'test': 4952,\n",
            "        'train': 2501,\n",
            "        'validation': 2510,\n",
            "    },\n",
            "    supervised_keys=None,\n",
            "    citation=\"\"\"@misc{pascal-voc-2007,\n",
            "    \tauthor = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
            "    \ttitle = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n",
            "    \thowpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n",
            "FeaturesDict({\n",
            "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
            "    'image/filename': Text(shape=(), dtype=tf.string),\n",
            "    'labels': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
            "    'labels_no_difficult': Sequence(ClassLabel(shape=(), dtype=tf.int64, num_classes=20)),\n",
            "    'objects': Sequence({\n",
            "        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
            "        'is_difficult': Tensor(shape=(), dtype=tf.bool),\n",
            "        'is_truncated': Tensor(shape=(), dtype=tf.bool),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=20),\n",
            "        'pose': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
            "    }),\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlod_ENfMGm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8Q9CZ_GTnyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(inputs, convs, skip=True):\n",
        "\tplaceholder = inputs\n",
        "\tcount = 0\n",
        "\tfor conv in convs:\n",
        "\t\tif count == (len(convs) - 2) and skip:\n",
        "\t\t\tskip_connection = placeholder\n",
        "\t\tcount += 1\n",
        "\t\tif conv['stride'] > 1: placeholder = ZeroPadding2D(((1,0),(1,0)))(placeholder) \n",
        "\t\tplaceholder = Conv2D(conv['filter'],\n",
        "\t\t\t\t   conv['kernel'],\n",
        "\t\t\t\t   strides=conv['stride'],\n",
        "\t\t\t\t   padding='valid' if conv['stride'] > 1 else 'same',\n",
        "\t\t\t\t   name='conv_' + str(conv['layer_idx']),\n",
        "\t\t\t\t   use_bias=False if conv['bnorm'] else True)(placeholder)\n",
        "\t\tif conv['bnorm']: placeholder = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(placeholder)\n",
        "\t\tif conv['leaky']: placeholder = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(placeholder)\n",
        "\treturn add([skip_connection, placeholder]) if skip else placeholder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt4tI_M9jMkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_yolov3_model(input_images):\n",
        "\tinput_image = Input(shape=(None, None, 3))\n",
        "\t# Layer  0 => 4\n",
        "\tx = conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "\t\t\t\t\t\t\t\t  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\t# Layer  5 => 8\n",
        "\tx = conv_block(x, [{'filter': 128, 'kernel' : 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "\t\t\t\t\t\t\t\t\t\t\t{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "\t\t\t\t\t\t{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\t# Layer  9 => 11\n",
        "\tx = conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "\t\t\t\t\t\t\t\t\t\t {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\t# Layer 12 => 15\n",
        "\tx = conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "\t\t\t\t\t\t\t\t\t\t {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "\t\t\t\t\t\t\t\t\t\t {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\t# Layer 16 => 36\n",
        "\tfor i in range(7):\n",
        "\t\tx = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\tskip_36 = x\n",
        "\t# Layer 37 => 40\n",
        "\tx = conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\t# Layer 41 => 61\n",
        "\tfor i in range(7):\n",
        "\t\tx = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\tskip_61 = x\n",
        "\t# Layer 62 => 65\n",
        "\tx = conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\t# Layer 66 => 74\n",
        "\tfor i in range(3):\n",
        "\t\tx = conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "\t\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\t# Layer 75 => 79\n",
        "\tx = conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "\t\t\t\t\t\t{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "\t\t\t\t\t\t{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\t# Layer 80 => 82\n",
        "\tyolo_82 = conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "\t\t\t\t\t\t\t  {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\t# Layer 83 => 86\n",
        "\tx = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_61])\n",
        "\t# Layer 87 => 91\n",
        "\tx = conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "\t\t\t\t\t\t{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "\t\t\t\t\t\t{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\t# Layer 92 => 94\n",
        "\tyolo_94 = conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "\t\t\t\t\t\t\t  {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\t# Layer 95 => 98\n",
        "\tx = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "\tx = UpSampling2D(2)(x)\n",
        "\tx = concatenate([x, skip_36])\n",
        "\t #Layer 99 => 106\n",
        "\tyolo_106 = conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "\t\t\t\t\t\t\t   {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "\t\t\t\t\t\t\t   {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "\t\t\t\t\t\t\t   {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\tmodel = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "\t#print(x)\n",
        "\t#print('model'+ str(model))\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf-akp1lMLB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_test, info = tfds.load(\"mnist\", split=\"test\", with_info=True)\n",
        "print(info)\n",
        "fig = tfds.show_examples(info, voc_test)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sl97g-rrVod",
        "colab_type": "code",
        "outputId": "b423225a-4778-4475-cb19-4f92b2b97a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNimpWsbrdjF",
        "colab_type": "code",
        "outputId": "e7a10164-b39c-438e-f448-ad38f3b1a835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a42075ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIQJ_hD4rhmj",
        "colab_type": "code",
        "outputId": "91c616b4-416e-4584-861f-5c533f99609f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBicAbUErj6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPQAZeoDrl9m",
        "colab_type": "code",
        "outputId": "d202553b-42de-4a63-a0bd-91b4d15d475f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUfDfvzIrn_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Nrs05Nrra3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYnJhVq7rydR",
        "colab_type": "code",
        "outputId": "00c485e6-f9c3-4296-b7d7-c1afb0b2a99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.2891 - accuracy: 0.9508 - val_loss: 0.0981 - val_accuracy: 0.9708\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.0746 - accuracy: 0.9776 - val_loss: 0.0931 - val_accuracy: 0.9734\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0921 - val_accuracy: 0.9734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7aa00f91d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8tiWzBesMpK",
        "colab_type": "code",
        "outputId": "424b7fef-5793-4511-88a3-08a109ed04fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWGngDOrr0WB",
        "colab_type": "code",
        "outputId": "c03cf1c4-406d-4a0a-8146-387dad0f081a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53KKgx6Fs9AQ",
        "colab_type": "code",
        "outputId": "199cfc39-6732-4150-87ae-71065aef34e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgbUKSE9tqx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_image = np.ones((100,100,3))\n",
        "new_image = np.ones((100,100,3,1))    \n",
        "\n",
        "# lets jsut say you have two Images \n",
        "old_image = np.reshape(old_image , (100,100,3,1))\n",
        "new_image = np.reshape(new_image , (100,100,3,1))\n",
        "directory = np.append( new_image , old_image , axis = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKQAg4Jzd_BT",
        "colab_type": "code",
        "outputId": "111538cd-6ab9-4410-f3f4-468efcd619b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "directory.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100, 3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty2T1KTyeE3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples = len(y_train)\n",
        "print(n_samples)\n",
        "Y_train = []\n",
        "for i in range(n_samples):\n",
        "  Y_train = np.append( Y_train , y_train[i+1][\"array\"])\n",
        "  #Y_train = np.append(Y_train, y_train[i+1][\"labels\"].astype(\"int\"))\n",
        "\n",
        "X_train= X_train.reshape((1,448, 448, 3))\n",
        "Y_train= Y_train.reshape((1,1,1,4))\n",
        "Y_train = Y_train.astype(\"float32\")\n",
        "print(Y_train.shape)\n",
        "print(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}