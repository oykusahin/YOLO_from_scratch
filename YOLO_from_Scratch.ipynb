{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_from_Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xk59v72Lb4U",
        "colab_type": "code",
        "outputId": "59e81e52-fd27-4df7-d800-3c11d8bd456a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.17.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlEH1PMO0PB",
        "colab_type": "code",
        "outputId": "c11b6055-29ef-4c62-e16d-a41f37856494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vLsrZ9esUX",
        "colab_type": "code",
        "outputId": "cca80f20-b3b0-4c17-f303-946baa5346a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "#REFERENCES FOR THE SOME METHODS OF THE CODE:\n",
        "#https://www.kaggle.com/aruchomu/yolo-v3-object-detection-in-tensorflow \n",
        "#https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display #for being able to displaying images in the notebook\n",
        "from seaborn import color_palette\n",
        "import cv2\n",
        "from tensorflow.python.keras.layers import Conv2D"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ7X41sbfB--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_BATCH_NORM_DECAY = 0.9                               #momentum (used for moving average and variance)\n",
        "_BATCH_NORM_EPSILON = 1e-05                           #epsilon for the formula\n",
        "_LEAKY_RELU = 0.1                                     #alpha for the leaky relu\n",
        "\n",
        "_ANCHORS = [(10, 13), (16, 30),   (33, 23),             #set of predefined bounding boxes of a certain width and height, were calculatedon the COCO\n",
        "            (30, 61), (62, 45),   (59, 119),            #dataset using k-means clustering. k-means: aims to partition n_observations into k clusters\n",
        "            (116, 90),(156, 198), (373, 326)]           #in which each observation belongs to the cluster\n",
        "            \n",
        "_MODEL_SIZE = (416, 416)                              #input shape of the vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GAmXxyAL1nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#after every CN layer there is a batch normalization\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "#TODO: Understand Batch Norm Better: https://www.youtube.com/watch?v=nUUqwaxLnWs\n",
        "\n",
        "def batch_norm(inputs, training, data_format):\n",
        "  return tf.layers.batch_normalization(inputs= inputs,\n",
        "                                       axis=1 if data_format =='channels_first'\n",
        "                                              else 3,\n",
        "                                       momentum = _BATCH_NORM_DECAY,\n",
        "                                       epsilon = _BATCH_NORM_EPSILON,\n",
        "                                       scale= True,\n",
        "                                       training= training\n",
        "                                       )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7VfZt6L7vdj",
        "colab_type": "text"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/batch_normalization\n",
        "\n",
        "Difference between kernel and filter: \n",
        "\n",
        "Kernel refers to a 2D Array of weights. The term filter is for 3D shortcuts of multiple kernels stacked together. \n",
        "For a 2D filter, filter is same as kernel,\n",
        "For a 3D filter, filter is collection of kernels. \n",
        "\n",
        "![Difference between kernel and filter](https://miro.medium.com/max/1829/1*NCDUVdTGF3hu6zrzdYFqJA.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FE6kQXYz1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "  pad_total= kernel_size -1\n",
        "  pad_beg = pad_total // 2 #Floor division i.e: 19//2 = 8, 15//2 = 7\n",
        "  pad_end = pad_total - pad_beg\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    padded_inputs = tf.pad(inputs, \n",
        "                           [[0, 0], \n",
        "                            [0, 0],\n",
        "                            [pad_beg, pad_end],\n",
        "                            [pad_beg, pad_end]]\n",
        "                           )\n",
        "  else:\n",
        "    padded_inputs = tf.pad(inputs, \n",
        "                           [[0, 0], \n",
        "                            [pad_beg, pad_end],\n",
        "                            [pad_beg, pad_end], \n",
        "                            [0, 0]]\n",
        "                           )\n",
        "    return padded_inputs                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1smDcqRaCYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://keras.io/layers/convolutional/\n",
        "#https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    if strides > 1:\n",
        "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "        \n",
        "    return tf.layers.conv2d(\n",
        "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
        "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
        "        use_bias=False, data_format=data_format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wuYM5NXbJnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#residual blocks: each layer feeds into the next layer and directly into the layers about 2–3 hops away.\n",
        "#leaky_relu: \n",
        "  #Dying ReLU problem: w= w- alpha*Z\n",
        "  #If learning rate is too high then it is possible for new w to be negative.\n",
        "  #If w is negative in ReLU then the result of the activation function will be zero.  \n",
        "  #here no gradient flows and if large number of dead neurons are there in a Neural Network it’s performance is affected \n",
        "  #thus causing a leak and extending the range of ReLU\n",
        "\n",
        "#data_format: channels_last or channels_first\n",
        "  #channels_last:  corresponds to inputs with shape (batch, height, width, channels)\n",
        "  #channels_first: corresponds to inputs with shape (batch, channels, height, width)\n",
        "\n",
        "def darknet53_residual_block(inputs, filters, training, data_format,\n",
        "                             strides=1):\n",
        "    shortcut = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(\n",
        "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
        "        data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs += shortcut\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wCwfvvhoGxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def darknet53(inputs, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3, data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = darknet53_residual_block(inputs, filters=32, training=training, data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(2):\n",
        "        inputs = darknet53_residual_block(inputs, filters=64,training=training, data_format=data_format)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=128, training=training, data_format=data_format)\n",
        "\n",
        "    route1 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(8):\n",
        "        inputs = darknet53_residual_block(inputs, filters=256, training=training,data_format=data_format)\n",
        "\n",
        "    route2 = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    for _ in range(4):\n",
        "        inputs = darknet53_residual_block(inputs, filters=512,training=training,data_format=data_format)\n",
        "\n",
        "    return route1, route2, inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mR0yN4_rZAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_convolution_block(inputs, filters, training, data_format):\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    route = inputs\n",
        "\n",
        "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
        "                                  data_format=data_format)\n",
        "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
        "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "\n",
        "    return route, inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKHJBEsUxZUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
        "    #print(img_size) = (416, 416)\n",
        "    n_anchors = len(anchors)\n",
        "    #print(n_anchors) = 3\n",
        "    #print(n_classes) = 80\n",
        "\n",
        "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
        "                              kernel_size=1, strides=1, use_bias=True,\n",
        "                              data_format=data_format)\n",
        "\n",
        "    shape = inputs.get_shape().as_list()\n",
        "    #print(shape) = [1, 255, 416, 416]\n",
        "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]    \n",
        "    #print(grid_shape) = [416, 416]\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "    ###############BLACKOUT#######################################################\n",
        "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1], 5 + n_classes])\n",
        "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
        "\n",
        "    box_centers, box_shapes, confidence, classes = \\\n",
        "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
        "    ###############BLACKOUT#######################################################\n",
        "\n",
        "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
        "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
        "    x_offset, y_offset = tf.meshgrid(x, y)              #tf.meshgrid(): Given N one-dimensional coordinate arrays, returns a list outputs of N-D coordinate arrays\n",
        "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
        "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
        "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1) #tf.concat(): Concatenates the list of tensors values along dimension axis\n",
        "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])      #tf.tile():This operation creates a new tensor by replicating input multiples times.\n",
        "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])       \n",
        "    box_centers = tf.nn.sigmoid(box_centers)\n",
        "    #print(box_centers) = Tensor(\"yolo_v3_model/Sigmoid_6:0\", shape=(1, 519168, 2), dtype=float32)\n",
        "    box_centers = (box_centers + x_y_offset) * strides\n",
        "\n",
        "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
        "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
        "\n",
        "    confidence = tf.nn.sigmoid(confidence)\n",
        "\n",
        "    classes = tf.nn.sigmoid(classes)\n",
        "\n",
        "    inputs = tf.concat([box_centers, box_shapes,\n",
        "                        confidence, classes], axis=-1)\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v-b4dZaUh8u",
        "colab_type": "text"
      },
      "source": [
        "One of the ways to upsample the compressed image is by Unpooling (the reverse of pooling) using Nearest Neighbor or by max unpooling.\n",
        "\n",
        "![alt text](https://kharshit.github.io/img/upsampling1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9UzPcaIb99R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Upsamples the feature map in the previous layer by a factor of stride using bilinear upsampling.\n",
        "def upsample(inputs, out_shape, data_format):\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
        "        new_height = out_shape[3]\n",
        "        new_width = out_shape[2]\n",
        "    else:\n",
        "        new_height = out_shape[2]\n",
        "        new_width = out_shape[1]\n",
        "\n",
        "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXvVfdQJcd_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_boxes(inputs):\n",
        "    center_x, center_y, width, height, confidence, classes = \\\n",
        "        tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)\n",
        "\n",
        "    top_left_x = center_x - width / 2\n",
        "    top_left_y = center_y - height / 2\n",
        "    bottom_right_x = center_x + width / 2\n",
        "    bottom_right_y = center_y + height / 2\n",
        "\n",
        "    boxes = tf.concat([top_left_x, top_left_y,\n",
        "                       bottom_right_x, bottom_right_y,\n",
        "                       confidence, classes], axis=-1)\n",
        "\n",
        "    return boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4lB4JNxchXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to discard the boxes with low confidence scores\n",
        "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold,\n",
        "                        confidence_threshold):\n",
        "    batch = tf.unstack(inputs)        #Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
        "    boxes_dicts = []\n",
        "    for boxes in batch:\n",
        "        boxes = tf.boolean_mask(boxes, boxes[:, 4] > confidence_threshold)  # tf.boolean_mask(): \n",
        "                                                                            # tensor = [0, 1, 2, 3]\n",
        "                                                                            # mask = np.array([True, False, True, False])\n",
        "                                                                            # boolean_mask(tensor, mask)  \n",
        "                                                                            # [0, 2]\n",
        "        classes = tf.argmax(boxes[:, 5:], axis=-1)                          # tf.argmax(): Returns the index with the largest value across axis of a tensor.\n",
        "        classes = tf.expand_dims(tf.to_float(classes), axis=-1)             # tf.expand_dims(): Returns a tensor with an additional dimension inserted at index axis.\n",
        "        boxes = tf.concat([boxes[:, :5], classes], axis=-1)                 \n",
        "\n",
        "        boxes_dict = dict()\n",
        "        for cls in range(n_classes):\n",
        "            mask = tf.equal(boxes[:, 5], cls)\n",
        "            mask_shape = mask.get_shape()\n",
        "            if mask_shape.ndims != 0:\n",
        "                class_boxes = tf.boolean_mask(boxes, mask)\n",
        "                boxes_coords, boxes_conf_scores, _ = tf.split(class_boxes,\n",
        "                                                              [4, 1, -1],\n",
        "                                                              axis=-1)\n",
        "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
        "                indices = tf.image.non_max_suppression(boxes_coords,\n",
        "                                                       boxes_conf_scores,\n",
        "                                                       max_output_size,\n",
        "                                                       iou_threshold)\n",
        "                class_boxes = tf.gather(class_boxes, indices)\n",
        "                boxes_dict[cls] = class_boxes[:, :5]\n",
        "\n",
        "        boxes_dicts.append(boxes_dict)\n",
        "\n",
        "    return boxes_dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FT3TW-eOxoVd",
        "colab": {}
      },
      "source": [
        "class Yolo_v3:\n",
        "    \"\"\"Yolo v3 model class.\"\"\"\n",
        "\n",
        "    def __init__(self, n_classes, model_size, max_output_size, iou_threshold,\n",
        "                 confidence_threshold, data_format=None):\n",
        "        \"\"\"Creates the model.\n",
        "\n",
        "        Args:\n",
        "            n_classes: Number of class labels.\n",
        "            model_size: The input size of the model.\n",
        "            max_output_size: Max number of boxes to be selected for each class.\n",
        "            iou_threshold: Threshold for the IOU.\n",
        "            confidence_threshold: Threshold for the confidence score.\n",
        "            data_format: The input format.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        if not data_format:\n",
        "            if tf.test.is_built_with_cuda():\n",
        "                data_format = 'channels_first'\n",
        "            else:\n",
        "                data_format = 'channels_last'\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.model_size = model_size\n",
        "        self.max_output_size = max_output_size\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.data_format = data_format\n",
        "\n",
        "    def __call__(self, inputs, training):\n",
        "        \"\"\"Add operations to detect boxes for a batch of input images.\n",
        "\n",
        "        Args:\n",
        "            inputs: A Tensor representing a batch of input images.\n",
        "            training: A boolean, whether to use in training or inference mode.\n",
        "\n",
        "        Returns:\n",
        "            A list containing class-to-boxes dictionaries\n",
        "                for each sample in the batch.\n",
        "        \"\"\"\n",
        "        with tf.variable_scope('yolo_v3_model'):\n",
        "            if self.data_format == 'channels_first':\n",
        "                inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "            inputs = inputs / 255\n",
        "\n",
        "            route1, route2, inputs = darknet53(inputs, training=training,\n",
        "                                               data_format=self.data_format)\n",
        "\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=512, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect1 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[6:9],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
        "                                          data_format=self.data_format)\n",
        "            inputs = batch_norm(inputs, training=training,\n",
        "                                data_format=self.data_format)\n",
        "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "            upsample_size = route2.get_shape().as_list()\n",
        "            inputs = upsample(inputs, out_shape=upsample_size,\n",
        "                              data_format=self.data_format)\n",
        "            axis = 1 if self.data_format == 'channels_first' else 3\n",
        "            inputs = tf.concat([inputs, route2], axis=axis)\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=256, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect2 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[3:6],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1,\n",
        "                                          data_format=self.data_format)\n",
        "            inputs = batch_norm(inputs, training=training,\n",
        "                                data_format=self.data_format)\n",
        "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
        "            upsample_size = route1.get_shape().as_list()\n",
        "            inputs = upsample(inputs, out_shape=upsample_size,\n",
        "                              data_format=self.data_format)\n",
        "            inputs = tf.concat([inputs, route1], axis=axis)\n",
        "            route, inputs = yolo_convolution_block(\n",
        "                inputs, filters=128, training=training,\n",
        "                data_format=self.data_format)\n",
        "            detect3 = yolo_layer(inputs, n_classes=self.n_classes,\n",
        "                                 anchors=_ANCHORS[0:3],\n",
        "                                 img_size=self.model_size,\n",
        "                                 data_format=self.data_format)\n",
        "\n",
        "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
        "\n",
        "            inputs = build_boxes(inputs)\n",
        "\n",
        "            boxes_dicts = non_max_suppression(\n",
        "                inputs, n_classes=self.n_classes,\n",
        "                max_output_size=self.max_output_size,\n",
        "                iou_threshold=self.iou_threshold,\n",
        "                confidence_threshold=self.confidence_threshold)\n",
        "\n",
        "            return boxes_dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhtMqVedcpuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_images(img_names, model_size):\n",
        "    imgs = []\n",
        "\n",
        "    for img_name in img_names:\n",
        "        img = Image.open(img_name)\n",
        "        img = img.resize(size=model_size)\n",
        "        img = np.array(img, dtype=np.float32)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        imgs.append(img)\n",
        "\n",
        "    imgs = np.concatenate(imgs)\n",
        "\n",
        "    return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtjdXYoFcsQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_class_names(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        class_names = f.read().splitlines()\n",
        "    return class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbLGdFrnzReT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_weights(variables, file_name):\n",
        "\n",
        "    with open(file_name, \"rb\") as f:\n",
        "        # Skip first 5 values containing irrelevant info\n",
        "        np.fromfile(f, dtype=np.int32, count=5)\n",
        "        weights = np.fromfile(f, dtype=np.float32)\n",
        "\n",
        "        assign_ops = []\n",
        "        ptr = 0\n",
        "\n",
        "        # Load weights for Darknet part.\n",
        "        # Each convolution layer has batch normalization.\n",
        "        for i in range(52):\n",
        "            conv_var = variables[5 * i]\n",
        "            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
        "            batch_norm_vars = [beta, gamma, mean, variance]\n",
        "\n",
        "            for var in batch_norm_vars:\n",
        "                shape = var.shape.as_list()\n",
        "                num_params = np.prod(shape)\n",
        "                var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "                ptr += num_params\n",
        "                assign_ops.append(tf.assign(var, var_weights))\n",
        "\n",
        "            shape = conv_var.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                (shape[3], shape[2], shape[0], shape[1]))\n",
        "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "        # Loading weights for Yolo part.\n",
        "        # 7th, 15th and 23rd convolution layer has biases and no batch norm.\n",
        "        ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
        "        unnormalized = [6, 13, 20]\n",
        "        for j in range(3):\n",
        "            for i in ranges[j]:\n",
        "                current = 52 * 5 + 5 * i + j * 2\n",
        "                conv_var = variables[current]\n",
        "                gamma, beta, mean, variance =  \\\n",
        "                    variables[current + 1:current + 5]\n",
        "                batch_norm_vars = [beta, gamma, mean, variance]\n",
        "\n",
        "                for var in batch_norm_vars:\n",
        "                    shape = var.shape.as_list()\n",
        "                    num_params = np.prod(shape)\n",
        "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "                    ptr += num_params\n",
        "                    assign_ops.append(tf.assign(var, var_weights))\n",
        "\n",
        "                shape = conv_var.shape.as_list()\n",
        "                num_params = np.prod(shape)\n",
        "                var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                    (shape[3], shape[2], shape[0], shape[1]))\n",
        "                var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "                ptr += num_params\n",
        "                assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
        "            shape = bias.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(bias, var_weights))\n",
        "\n",
        "            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
        "            shape = conv_var.shape.as_list()\n",
        "            num_params = np.prod(shape)\n",
        "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
        "                (shape[3], shape[2], shape[0], shape[1]))\n",
        "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
        "            ptr += num_params\n",
        "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
        "\n",
        "    return assign_ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNi-WY_c2Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
        "\n",
        "    colors = ((np.array(color_palette(\"hls\", 80)) * 255)).astype(np.uint8)\n",
        "    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names,\n",
        "                                         boxes_dicts):\n",
        "        img = Image.open(img_name)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        font = ImageFont.truetype(font='/content/gdrive/My Drive/Colab Notebooks/sample_data/coco.names/futur.ttf',\n",
        "                                  size=(img.size[0] + img.size[1]) // 100)\n",
        "        resize_factor = \\\n",
        "            (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
        "        for cls in range(len(class_names)):\n",
        "            boxes = boxes_dict[cls]\n",
        "            if np.size(boxes) != 0:\n",
        "                color = colors[cls]\n",
        "                for box in boxes:\n",
        "                    xy, confidence = box[:4], box[4]\n",
        "                    xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
        "                    x0, y0 = xy[0], xy[1]\n",
        "                    thickness = (img.size[0] + img.size[1]) // 200\n",
        "                    for t in np.linspace(0, 1, thickness):\n",
        "                        xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
        "                        xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
        "                        draw.rectangle(xy, outline=tuple(color))\n",
        "                    text = '{} {:.1f}%'.format(class_names[cls],\n",
        "                                               confidence * 100)\n",
        "                    text_size = draw.textsize(text, font=font)\n",
        "                    draw.rectangle(\n",
        "                        [x0, y0 - text_size[1], x0 + text_size[0], y0],\n",
        "                        fill=tuple(color))\n",
        "                    draw.text((x0, y0 - text_size[1]), text, fill='black',\n",
        "                              font=font)\n",
        "\n",
        "        display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCO3t1vfIZJC",
        "colab_type": "code",
        "outputId": "b2459c44-d46d-4487-bcc5-ce49b9741d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "img_names = ['/content/gdrive/My Drive/Colab Notebooks/sample_data/__results___31_0.jpg']\n",
        "#for img in img_names: display(Image.open(img))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5_NQKbSJ9Dx",
        "colab_type": "code",
        "outputId": "e76bd8be-49c3-4fa5-a92f-5d1eef55887f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "batch_size = len(img_names)\n",
        "batch = load_images(img_names, model_size=_MODEL_SIZE)\n",
        "data_format= 'channels_first'\n",
        "class_names = load_class_names('/content/gdrive/My Drive/Colab Notebooks/sample_data/coco.names')\n",
        "if batch is None:\n",
        "    print(\"imread failed on {}\".format(img))\n",
        "n_classes = len(class_names)\n",
        "max_output_size = 10\n",
        "iou_threshold = 0.5\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE,\n",
        "                max_output_size=max_output_size,\n",
        "                iou_threshold=iou_threshold,\n",
        "                confidence_threshold=confidence_threshold,data_format=data_format)\n",
        "\n",
        "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
        "\n",
        "detections = model(inputs, training=False)\n",
        "\n",
        "model_vars = tf.global_variables(scope='yolo_v3_model')\n",
        "assign_ops = load_weights(model_vars, '/content/gdrive/My Drive/Colab Notebooks/sample_data/yolov3.weights')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(assign_ops)\n",
        "    detection_result = sess.run(detections, feed_dict={inputs: batch})\n",
        "    \n",
        "draw_boxes(img_names, detection_result, class_names, _MODEL_SIZE)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-126085ef4139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yolo_v3_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b82d912a33ed>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             route1, route2, inputs = darknet53(inputs, training=training,\n\u001b[0;32m---> 50\u001b[0;31m                                                data_format=self.data_format)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             route, inputs = yolo_convolution_block(\n",
            "\u001b[0;32m<ipython-input-9-fdd5afe4a58d>\u001b[0m in \u001b[0;36mdarknet53\u001b[0;34m(inputs, training, data_format)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdarknet53\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d_fixed_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_LEAKY_RELU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2d_fixed_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-0ffd68beef12>\u001b[0m in \u001b[0;36mconv2d_fixed_padding\u001b[0;34m(inputs, filters, kernel_size, data_format, strides)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SAME'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'VALID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         use_bias=False, data_format=data_format)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    422\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m       _scope=name)\n\u001b[0;32m--> 424\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1698\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \"\"\"\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable yolo_v3_model/conv2d/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DCJDjxYExqsH",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}